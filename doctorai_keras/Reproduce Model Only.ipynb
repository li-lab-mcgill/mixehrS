{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kernel is different from \"Reproduce Preprocessing and Modelling\" since it takes the same input as the original Theano model, but uses a new Keras architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Dense, GRU, Embedding, Dropout, Masking, GlobalMaxPooling1D, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"9\"\n",
    "\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(file):\n",
    "    with open(file, 'rb') as f:\n",
    "        loaded = pickle.load(f, encoding='latin1')\n",
    "       \n",
    "    return loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the files\n",
    "full_icd9_seqs = load_file('../doctorai/full_icd9.seqs')\n",
    "full_icd9_dates = load_file('../doctorai/full_icd9.dates')\n",
    "full_icd9_pids = load_file('../doctorai/full_icd9.pids')\n",
    "full_icd9_types = load_file('../doctorai/full_icd9.types')\n",
    "\n",
    "small_icd9_seqs = load_file('../doctorai/3digit_icd9.seqs')\n",
    "small_icd9_dates = load_file('../doctorai/3digit_icd9.dates')\n",
    "small_icd9_pids = load_file('../doctorai/3digit_icd9.pids')\n",
    "small_icd9_types = load_file('../doctorai/3digit_icd9.types')\n",
    "\n",
    "\n",
    "# Generating train-val-test indices\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "\n",
    "indices = list(range(len(full_icd9_seqs)))\n",
    "random.seed(2019)\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_split =  int(train_ratio * len(full_icd9_seqs))\n",
    "val_split = int(val_ratio * len(full_icd9_seqs))\n",
    "train_idx = indices[:train_split]\n",
    "val_idx = indices[train_split:train_split+val_split]\n",
    "test_idx = indices[train_split+val_split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits = [ls[:-1] for ls in full_icd9_seqs]\n",
    "labels = [ls[1:] for ls in small_icd9_seqs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of visits per patient: 41\n",
      "Max number of diagnosis in a visit: 39\n"
     ]
    }
   ],
   "source": [
    "n_visits_max = max([len(visit) for visit in visits])\n",
    "n_diagnosis_max = max([max(map(len, visit)) for visit in visits])\n",
    "\n",
    "print(\"Max number of visits per patient:\", n_visits_max)\n",
    "print(\"Max number of diagnosis in a visit:\", n_diagnosis_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7537, 41, 39)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visits_padded = pad_sequences([\n",
    "    pad_sequences(visit, maxlen=n_diagnosis_max) \n",
    "    for visit in visits\n",
    "])\n",
    "\n",
    "visits_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label encoding and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiLabelBinarizer(classes=None, sparse_output=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_flat = []\n",
    "for label in labels:\n",
    "    labels_flat.extend(label)\n",
    "\n",
    "label_enc = MultiLabelBinarizer()\n",
    "label_enc.fit(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7537, 41, 846)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_padded = pad_sequences([label_enc.transform(label) for label in labels])\n",
    "labels_padded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training patients: 6029 6029\n",
      "Number of validation patients: 753 753\n",
      "Number of test patients: 755 755\n"
     ]
    }
   ],
   "source": [
    "X_train = visits_padded[train_idx]\n",
    "X_val = visits_padded[val_idx]\n",
    "X_test = visits_padded[test_idx]\n",
    "\n",
    "y_train = labels_padded[train_idx]\n",
    "y_val = labels_padded[val_idx]\n",
    "y_test = labels_padded[test_idx]\n",
    "\n",
    "print(\"Number of training patients:\", len(X_train), len(y_train))\n",
    "print(\"Number of validation patients:\", len(X_val), len(y_val))\n",
    "print(\"Number of test patients:\", len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_recall(y_true, y_pred, use_tqdm=True, k=30):\n",
    "    pred_flat = y_pred.reshape(-1, 846)\n",
    "    true_flat = y_true.reshape(-1, 846)\n",
    "    \n",
    "    all_patients_recall = []\n",
    "\n",
    "    for adm_idx in tqdm(range(true_flat.shape[0]), disable=not use_tqdm):\n",
    "        true_indices = np.argwhere(true_flat[adm_idx] == 1).reshape(-1)\n",
    "\n",
    "        # If this admission does not have any diagnosis, then it\n",
    "        # is a dummy admission created by padding from keras\n",
    "        if true_indices.shape[0] > 0:\n",
    "            pred_indices = pred_flat[adm_idx].argsort()[-k:]\n",
    "\n",
    "            intersection_count = len(np.intersect1d(pred_indices, true_indices))\n",
    "\n",
    "            recall = intersection_count / len(true_indices)\n",
    "            all_patients_recall.append(recall)\n",
    "\n",
    "    all_patients_recall = np.array(all_patients_recall)\n",
    "    return all_patients_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom callback to monitor top-k recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopKRecallCallback(Callback):\n",
    "    def __init__(self, X_test, y_test):\n",
    "        super().__init__()\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.test_recalls_at_10 = []\n",
    "        self.test_recalls_at_20 = []\n",
    "        self.test_recalls_at_30 = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.X_test, batch_size=512)\n",
    "        y_test = self.y_test\n",
    "        \n",
    "        _test_recall_at_10 = top_k_recall(y_test, y_pred, k=10, use_tqdm=False).mean()\n",
    "        _test_recall_at_20 = top_k_recall(y_test, y_pred, k=20, use_tqdm=False).mean()\n",
    "        _test_recall_at_30 = top_k_recall(y_test, y_pred, k=30, use_tqdm=False).mean()\n",
    "        \n",
    "        self.test_recalls_at_10.append(_test_recall_at_10)\n",
    "        self.test_recalls_at_20.append(_test_recall_at_20)\n",
    "        self.test_recalls_at_30.append(_test_recall_at_30)\n",
    "\n",
    "        print(f\"\\ntest_top_k_recall: {_test_recall_at_10:.4f}@10; {_test_recall_at_20:.4f}@20; {_test_recall_at_30:.4f}@30\")\n",
    "\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_words, embedding_dim=200):\n",
    "    input1 = Input(shape=(None, None))\n",
    "    x = Embedding(num_words, embedding_dim, mask_zero=False)(input1)\n",
    "    x = K.sum(x, axis=2)\n",
    "    x = Masking(0)(x)\n",
    "    \n",
    "    x = GRU(200, return_sequences=True)(x)\n",
    "    x = GRU(200, return_sequences=True)(x)\n",
    "    \n",
    "    x = Dense(300, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(846, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=input1, outputs=x)\n",
    "    model.compile('adam', loss='binary_crossentropy')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4892"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words = max([X_train.max(), X_val.max(), X_test.max()]) + 1\n",
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, None, None)]      0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, None, None, 200)   978400    \n",
      "_________________________________________________________________\n",
      "tf_op_layer_Sum_2 (TensorFlo [(None, None, 200)]       0         \n",
      "_________________________________________________________________\n",
      "masking_2 (Masking)          (None, None, 200)         0         \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, None, 200)         241200    \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, None, 200)         241200    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, None, 300)         60300     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 300)         0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, None, 846)         254646    \n",
      "=================================================================\n",
      "Total params: 1,775,746\n",
      "Trainable params: 1,775,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(num_words)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6029 samples\n",
      "Epoch 1/10\n",
      " - test_top_k_recall: 0.2773@10; 0.4125@20; 0.4966@30\n",
      "6029/6029 - 7s - loss: 0.0043\n",
      "Epoch 2/10\n",
      " - test_top_k_recall: 0.2873@10; 0.4203@20; 0.5111@30\n",
      "6029/6029 - 7s - loss: 0.0043\n",
      "Epoch 3/10\n",
      " - test_top_k_recall: 0.2958@10; 0.4313@20; 0.5261@30\n",
      "6029/6029 - 7s - loss: 0.0042\n",
      "Epoch 4/10\n",
      " - test_top_k_recall: 0.3015@10; 0.4419@20; 0.5320@30\n",
      "6029/6029 - 7s - loss: 0.0042\n",
      "Epoch 5/10\n",
      " - test_top_k_recall: 0.3134@10; 0.4489@20; 0.5375@30\n",
      "6029/6029 - 7s - loss: 0.0042\n",
      "Epoch 6/10\n",
      " - test_top_k_recall: 0.3090@10; 0.4466@20; 0.5400@30\n",
      "6029/6029 - 7s - loss: 0.0042\n",
      "Epoch 7/10\n",
      " - test_top_k_recall: 0.3233@10; 0.4629@20; 0.5569@30\n",
      "6029/6029 - 7s - loss: 0.0042\n",
      "Epoch 8/10\n",
      " - test_top_k_recall: 0.3270@10; 0.4728@20; 0.5640@30\n",
      "6029/6029 - 7s - loss: 0.0042\n",
      "Epoch 9/10\n",
      " - test_top_k_recall: 0.3296@10; 0.4757@20; 0.5667@30\n",
      "6029/6029 - 7s - loss: 0.0041\n",
      "Epoch 10/10\n",
      " - test_top_k_recall: 0.3393@10; 0.4841@20; 0.5738@30\n",
      "6029/6029 - 7s - loss: 0.0041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcd6a5ec4d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    TopKRecallCallback(X_test=X_test, y_test=y_test)\n",
    "]\n",
    "\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    batch_size=64, \n",
    "    epochs=10, \n",
    "    verbose=2,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.1 s, sys: 59.4 s, total: 1min 18s\n",
      "Wall time: 2.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.device('/gpu:0'):\n",
    "    y_train_pred = model.predict(X_train, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 247189/247189 [00:03<00:00, 74653.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5995579711625877"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_patients_recall = top_k_recall(y_true=y_train, y_pred=y_train_pred)\n",
    "all_patients_recall.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.61 s, sys: 2.68 s, total: 4.29 s\n",
      "Wall time: 285 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tf.device('/gpu:0'):\n",
    "    y_pred = model.predict(X_test, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30955/30955 [00:00<00:00, 64654.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5737620405124925"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_patients_recall = top_k_recall(y_true=y_test, y_pred=y_pred)\n",
    "all_patients_recall.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval using DoctorAI metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recallTop(y_true, y_pred, rank=[10, 20, 30]):\n",
    "    y_pred = y_pred.reshape(-1, 846)\n",
    "    y_true = y_true.reshape(-1, 846)\n",
    "    \n",
    "    recall = list()\n",
    "    for i in range(len(y_pred)):\n",
    "        thisOne = list()\n",
    "        codes = y_true[i]\n",
    "        tops = y_pred[i]\n",
    "        for rk in rank:\n",
    "            thisOne.append(len(set(codes).intersection(set(tops[:rk])))*1.0/len(set(codes)))\n",
    "        recall.append( thisOne )\n",
    "    return (np.array(recall)).mean(axis=0).tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
