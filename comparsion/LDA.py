import pickleimport randomimport traceback import numpy as np import pandas as pd from tqdm import tqdm # tells you loop progressfrom corpus import Corpusfrom metrics import precision_recall_curve_metric, roc_curve_metricfrom sklearn.decomposition import LatentDirichletAllocationfrom sklearn.linear_model import LogisticRegressionfrom sklearn.model_selection import train_test_splittry:    with open('./store/corpus.pkl', "rb") as rbfile:        patients_data = pickle.load(rbfile)         rbfile.close() except Exception as e:     traceback.print_exc()        # Obtain patient list patients = {p[0].patient_id:p[0].words_dict for p in patients_data}label = []for p in patients_data:    label.append(p[0].y)def aggregate_dict_on_y(tup_dict):    # create new dictionary     new_dict = {}    # loop through each of the tup_dict keys      for x, y in tup_dict.keys():        # obtain z value         z = tup_dict[(x,y)]        # new (key,value) pair is (y,agg), where agg is the aggregated sum of         # all values for y. We can just add back at each iteration!        # if key not present in dictionary, add it         if y not in new_dict:             new_dict[y] = z         else:             # else add to previous value             new_dict[y] += z # extract value and add to the map    return new_dict# Now, we want to use this function to loop over every patient and get the unique ids p_dicts = {pid:aggregate_dict_on_y(words_dict) for pid,words_dict in patients.items() }# Now we need to obtain all the unique 'y' keys unique_ys = sorted({y for tdict in p_dicts.values() for y in tdict.keys()})# Now, we will simply fill every dictionary in p_dicts by putting 0 if the key is not existent for pid, p_dict in tqdm(p_dicts.items(), desc="looping..."):     for y in unique_ys:         # if y is not a key in that dictionary         if y not in p_dict:             # create that value and assign 0             p_dicts[pid][y] = 0 # now need to form a matrix of size DxV where D is the number of patients. # so every row will be a patient, every column will be a unique value. # since every dictionary in p_dicts now have the same keys, we can simply # pass this to a pandas DataFramedf = pd.DataFrame(p_dicts).T# can order this too cols = sorted(df.columns) df = df[cols]# df.to_csv('processed_corpus.csv', index=False)# df = pd.read_csv("processed_corpus.csv", index_col=0)# LDAlda = LatentDirichletAllocation(n_components=40, random_state = 0)lda.fit(df.values)LDA_df = lda.transform(df.values)# train test splitX_train, X_test, y_train, y_test = train_test_split(LDA_df, label, test_size=0.20, random_state=10)# evaluate on validattion test to find best number of topics# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.125, random_state=1)# clf = LogisticRegression(random_state=0).fit(X_val, y_val)# predicted_result = clf.predict_proba(X_test)[:, 0]# precision_recall_curve_metric(y_test, predicted_result, plot=True)clf = LogisticRegression(random_state=0).fit(X_train, y_train)predicted_result = clf.predict_proba(X_test)[:, 0]precision_recall_curve_metric(y_test, predicted_result, plot=True)roc_curve_metric(y_test, predicted_result, plot=True)